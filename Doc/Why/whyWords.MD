## From Text to Words

Both Forth and Python receive lines of text input. Both Forth and Python break the input into _tokens_. Tokens are the simplest parts of code that have some meaning. For example, the symbol `+` is a token.

The difference comes in how they do it.

### The Python Way

If you want to understand how Python does it, you'll have to read [15 pages of text](https://docs.python.org/3/reference/lexical_analysis.html) (4,430 words as of 2020-06-19), as well as some cross-references. The first bit is

>2. Lexical analysis
>
> A Python program is read by a parser. Input to the parser is a stream of tokens, generated by the lexical analyzer. This chapter describes how the lexical analyzer breaks a file into tokens.
>
> Python reads program text as Unicode code points; the encoding of a source file can be given by an encoding declaration and defaults to UTF-8, see PEP 3120 for details. If the source file cannot be decoded, a SyntaxError is raised.

If you are willing to read the next several thousand words of that specification, you will begin to understand how Python forms tokens.

### The Forth Way

Here's how Forth forms tokens:

1. Tokens are separated by whitespace (including space, tab, etc.).

2. The sequence `\` (backslash) followed by any amount of whitespace considered a "graphic space" (influence: [LATEX](https://www.latex-project.org/)), _not_ whitespace.

That's it.

([continue to next section](https://github.com/dmparrishphd/Python4th/blob/master/Doc/Why/whyMeaning.MD))
